<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://keaton.blue/feed.xml" rel="self" type="application/atom+xml"/><link href="https://keaton.blue/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-08-25T19:54:34+00:00</updated><id>https://keaton.blue/feed.xml</id><title type="html">Keaton Shurilla</title><subtitle>Personal web for researcher and artist Keaton Shurilla. </subtitle><entry><title type="html">AI is the hottest media</title><link href="https://keaton.blue/blog/2024/AI-is-the-hottest-media/" rel="alternate" type="text/html" title="AI is the hottest media"/><published>2024-05-24T00:00:00+00:00</published><updated>2024-05-24T00:00:00+00:00</updated><id>https://keaton.blue/blog/2024/AI-is-the-hottest-media</id><content type="html" xml:base="https://keaton.blue/blog/2024/AI-is-the-hottest-media/"><![CDATA[<p>Marshall McLuhan’s ever prophetic book <em>Understanding Media: The Extensions of Man</em><sup>1</sup> discusses two types of media—hot and cold. Cold media is low definition and hot media is high definition. Cold media requires the user to supplement the lack of fidelity, to mentally fill in the blanks. Hot media fills your senses and leaves less to the imagination. AI, or more specifically human-AI interaction, is especially comprehensible in terms of McLuhan’s hot and cold media. Which is it?</p> <p>Indeed, there may be many modalities in which AI-based information is channeled. In terms of sensory information, some are hotter (VR headsets) and some are colder (chatbots) than others. But the fundamental component of interactive AI is that we are allowing the machine to think for us. By definition, this makes AI white hot—<strong><em>AI is the hottest media</em></strong>. Essentially, we are asking the computer to fill in the blanks for us.</p> <p>To some extent, all media thinks for us. Even a blank piece of paper is used as a tool for thought, and this extended and externalized view of the mind has been intriguingly argued.<sup>2</sup> But a piece of paper doesn’t talk back to you. Even a video game or interactive video has a predetermined set of responses. AI seems to supersede Alan Kay’s idea of a “reactive engine” as described in the first sentence of his PhD thesis—”The design of machines which can participate in an interactive dialogue is the main topic of this thesis.”<sup>3</sup> AI is a “proactive” engine.</p> <p>All of this begs the follow-up question: can AI be made cold to demand more of us? That, to me, is the most interesting research question in human-AI interaction. Even if AI is made to be more demanding—perhaps through cognitive forcing<sup>4</sup>—we are still leasing the direction of our thoughts to a proactive entity. It’s direct manipulation vs. interface agents all over again.</p> <hr/> <h3 id="references">References</h3> <ol> <li>McLuhan, M. <em>Understanding Media: The Extensions of Man</em>. (MIT Press, 1994).</li> <li>Clark, A. &amp; Chalmers, D. The Extended Mind. <em>Analysis</em> <strong>58</strong>, 7–19 (1998).</li> <li>Kay, A. C. The Reactive Engine. (University of Utah, 1969).</li> <li>Buçinca, Z., Malaya, M. B. &amp; Gajos, K. Z. To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making. <em>Proc. ACM Hum.-Comput. Interact.</em> <strong>5</strong>, 1–21 (2021).</li> </ol>]]></content><author><name></name></author><category term="academics"/><category term="research"/><category term="AI"/><category term="media"/><summary type="html"><![CDATA[AI in terms of McLuhan's hot and cold media]]></summary></entry><entry><title type="html">Immersion learning applies to academic subjects, not just languages</title><link href="https://keaton.blue/blog/2024/academic_immersion/" rel="alternate" type="text/html" title="Immersion learning applies to academic subjects, not just languages"/><published>2024-05-18T00:00:00+00:00</published><updated>2024-05-18T00:00:00+00:00</updated><id>https://keaton.blue/blog/2024/academic_immersion</id><content type="html" xml:base="https://keaton.blue/blog/2024/academic_immersion/"><![CDATA[<p>It is difficult to learn dense technical subjects. Where do you begin, when there’s an ocean of resources and a variety of projects to tackle? Immersion based language learning offers a good model.</p> <h2 id="the-input-hypothesis">The Input Hypothesis</h2> <p>The idea of learning via massive amounts of input has gained popularity in language learning circles. The general trend is to bootstrap an initial learning period with a targeted amount of study, and then learn through immersion in normal content geared towards native speakers. This process can be paired with a spaced repetition system (e.g. anki) to speed up acquisition. The result is that output in a language—speaking and writing—is a function of input—listening and reading.</p> <p>For example, in Japanese a learner might:</p> <ol> <li>Learn vocabulary using an anki deck with the most common 2000 words</li> <li>Begin exposure through subtitled anime</li> <li>Progress to reading full books</li> <li>Continually learn through all types of media</li> </ol> <p>Indeed, this is more or less what I did to pass the N1 on the Japanese Language Proficiency Test.</p> <p>Number two above highlights the idea of “comprehensible input.” That is, the chance of comprehending the media should be maximized with supplements. Subtitled anime is a good example, because the person watching is simultaneously exposed to the spoken language (audio), the written language (subtitles), and the visual content of what is being described (the anime). If the content is barely comprehended then the learner doesn’t learn much! Which is why jumping straight into reading full books probably isn’t the most efficient learning method. The input should roughly match the learners ability.</p> <h2 id="immersion-machine-learning">Immersion Machine Learning</h2> <p>How can we apply this idea to an academic subject? With the same general idea—a period of targeted study at the outset, followed by learning through immersion.</p> <p>Let’s use machine learning as an example:</p> <ol> <li>Work through an introductory text, such as ISL<sup>1</sup></li> <li>Follow along with some Jupyter notebook tutorials using real code</li> <li>Build your first project from scratch, targeting a real problem</li> <li>Keep building while continually immersing in new papers, referencing textbooks when you get stuck, etc.</li> </ol> <p>Step one allows you to gain familiarity with the new vocabulary and concepts. Step two is a form of comprehensible input—looking at real code made more comprehensible by explanations and experimentation. The rest is akin to immersing yourself in a language, or simply living in an environment with constant opportunities for input and output.</p> <p>This provides a powerful way to overcome endlessly building up base knowledge through textbooks and courses. At some point, you have to jump into the deep end and learn how to swim. By purposely placing a limit on the initial bootstrap step you can overcome paralysis by analysis. This echoes some of the advice in the academia stack exchange post <a href="https://academia.stackexchange.com/questions/89032/how-to-stop-hopping-the-learning-chain-and-actually-begin-somewhere">How to stop hopping the learning chain and actually begin somewhere?</a></p> <p>The key challenge here is to identify what a good introductory resource is, and to set a hard limit on getting through it in a timely fashion.</p> <h2 id="bottom-up-or-top-down">Bottom-up or Top-down?</h2> <p>The textbook Mathematics for Machine Learning<sup>2</sup> by Deisenroth, Faisal, and Ong contains a discussion at the outset on bottom-up vs. top-down learning. Similar to inductive vs. deductive learning, they give the following definitions:</p> <ul> <li><strong>Bottom-up:</strong> Building up the concepts from foundational to more advanced.</li> <li><strong>Top-down:</strong> Drilling down from practical needs to more basic requirements.</li> </ul> <p>While doing everything bottom-up seems logical, it’s hard to deny the power of learning by doing. Projects are essential to mastery—you won’t learn to swim just by reading about swimming. But, it is deeply frustrating to try to make something with insufficient background knowledge. Tightly targeted learning at the outset saves the headache of endlessly starting and abandoning learning resources and projects. Start with an appropriate amount of bottom-up before progressing into top-down, and then reference bottom-level concepts as needed to make progress.</p> <p>P.S. You just read the first post on my blog! Thanks for swinging by.</p> <hr/> <h2 id="references">References</h2> <ol> <li>James, G., Witten, D., Hastie, T., Tibshirani, R. &amp; Taylor, J. E. <em>An introduction to statistical learning: with applications in Python</em>. (Springer, 2023).</li> <li>Deisenroth, M. P., Faisal, A. A. &amp; Ong, C. S. <em>Mathematics for Machine Learning</em>. (2020).</li> </ol>]]></content><author><name></name></author><category term="academics"/><category term="research"/><category term="language-learning"/><category term="learning"/><summary type="html"><![CDATA[Applying the input hypothesis to efficiently learn technical subjects]]></summary></entry></feed>